{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flash-flood User Vignette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[flash-flood](https://github.com/HumanCellAtlas/flash-flood) is an event recorder and streamer built on top of AWS S3, supporting distributed writes and fast distributed bulk reads. It can be used to store and retrieve information about transactions and events in JSON format, which can be quickly filtered with JMESPath. In this notebook we demonstrate basic usage of the flash-flood library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started by instantiating an instance of the FlashFlood class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "from flashflood import FlashFlood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flash-flood reads and writes events from a journal that is stored in an S3 bucket, so you must provide flash-flood with the name of an S3 bucket you have read/write access to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = FlashFlood(s3, \"my-flashflood-test-bucket\", \"my_prefix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a flash-flood event by providing flash-flood with event data, a unique event identifier, and a timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import uuid\n",
    "\n",
    "event_data = b'my event data'\n",
    "event_uuid = str(uuid.uuid4())\n",
    "event_date = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flash-flood exposes a CRUD API to access event information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded journal 2020-03-23T165426.235201Z--2020-03-23T165426.235201Z--new--bb66c684-5592-48ce-a4bf-518331754812\n",
      "new journal 2020-03-23T165426.235201Z--2020-03-23T165426.235201Z--new--bb66c684-5592-48ce-a4bf-518331754812\n",
      "This is the data: b'my event data'\n",
      "This is the date: 2020-03-23 16:54:26.235201\n",
      "This is the event ID: 6438b1e0-4cde-4b39-81f3-098e30bc3ef3\n",
      "This is the updated data: b'my event data'\n"
     ]
    }
   ],
   "source": [
    "# Create\n",
    "ff.put(event_data, event_uuid, event_date)\n",
    "\n",
    "# Read\n",
    "event = ff.get_event(event_uuid)\n",
    "print(\"This is the data: \" + str(event.data))\n",
    "print(\"This is the date: \" + str(event.date))\n",
    "print(\"This is the event ID: \" + event.event_id)\n",
    "\n",
    "# Update\n",
    "new_event_data = b'i want to put new data'\n",
    "ff.update_event(event_uuid, new_event_data)\n",
    "print(\"This is the updated data: \" + str(ff.get_event(event_uuid).data))\n",
    "\n",
    "# Delete\n",
    "ff.delete_event(event_uuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All events belong to a journal. Journals can be created ad-hoc or manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found journal to combine 2020-03-23T165426.235201Z--2020-03-23T165426.235201Z--new--bb66c684-5592-48ce-a4bf-518331754812\n",
      "combining journal 2020-03-23T165426.235201Z--2020-03-23T165426.235201Z--new--bb66c684-5592-48ce-a4bf-518331754812\n"
     ]
    }
   ],
   "source": [
    "ff.journal(minimum_number_of_events=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Journals can also be listed using the `ff.list_journals()` function in flash-flood.\n",
    "\n",
    "When events are created, they are assigned a date. You can create a stream of all events that have occurred between two given dates. The code below creates fake events, then creates a stream between two dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded journal 1970-01-05T070640.000000Z--1970-01-05T070640.000000Z--new--9cce73cc-c1a4-4bcd-84c0-a5ddb6ac715f\n",
      "new journal 1970-01-05T070640.000000Z--1970-01-05T070640.000000Z--new--9cce73cc-c1a4-4bcd-84c0-a5ddb6ac715f\n",
      "Uploaded journal 1970-01-05T095320.000000Z--1970-01-05T095320.000000Z--new--321bdb37-a911-4765-8340-70e4d093667e\n",
      "new journal 1970-01-05T095320.000000Z--1970-01-05T095320.000000Z--new--321bdb37-a911-4765-8340-70e4d093667e\n",
      "Uploaded journal 1970-01-05T124000.000000Z--1970-01-05T124000.000000Z--new--a5b94332-a395-4da1-a4c9-7a867ddc53f6\n",
      "new journal 1970-01-05T124000.000000Z--1970-01-05T124000.000000Z--new--a5b94332-a395-4da1-a4c9-7a867ddc53f6\n",
      "Uploaded journal 1970-01-05T152640.000000Z--1970-01-05T152640.000000Z--new--3288da4a-17f1-44d4-8d5c-865ec84fdfdd\n",
      "new journal 1970-01-05T152640.000000Z--1970-01-05T152640.000000Z--new--3288da4a-17f1-44d4-8d5c-865ec84fdfdd\n",
      "Uploaded journal 1970-01-05T181320.000000Z--1970-01-05T181320.000000Z--new--894d9c62-fdae-4f9b-ba2f-c0d8d09303e1\n",
      "new journal 1970-01-05T181320.000000Z--1970-01-05T181320.000000Z--new--894d9c62-fdae-4f9b-ba2f-c0d8d09303e1\n",
      "Uploaded journal 1970-01-05T210000.000000Z--1970-01-05T210000.000000Z--new--5bfe0732-2fa8-483f-b7d0-9b83cf19f194\n",
      "new journal 1970-01-05T210000.000000Z--1970-01-05T210000.000000Z--new--5bfe0732-2fa8-483f-b7d0-9b83cf19f194\n",
      "Uploaded journal 1970-01-05T234640.000000Z--1970-01-05T234640.000000Z--new--05e2ab49-410c-405a-b3ab-7a2da4f2805d\n",
      "new journal 1970-01-05T234640.000000Z--1970-01-05T234640.000000Z--new--05e2ab49-410c-405a-b3ab-7a2da4f2805d\n",
      "Uploaded journal 1970-01-06T023320.000000Z--1970-01-06T023320.000000Z--new--ab5ed194-92bc-448b-afee-7cdb22ba0ada\n",
      "new journal 1970-01-06T023320.000000Z--1970-01-06T023320.000000Z--new--ab5ed194-92bc-448b-afee-7cdb22ba0ada\n",
      "Uploaded journal 1970-01-06T052000.000000Z--1970-01-06T052000.000000Z--new--59c3cad0-af15-41f4-b5d2-3a438841d3cd\n",
      "new journal 1970-01-06T052000.000000Z--1970-01-06T052000.000000Z--new--59c3cad0-af15-41f4-b5d2-3a438841d3cd\n",
      "Uploaded journal 1970-01-06T080640.000000Z--1970-01-06T080640.000000Z--new--fa0cfd86-c605-4ada-ba3a-1708e75fc876\n",
      "new journal 1970-01-06T080640.000000Z--1970-01-06T080640.000000Z--new--fa0cfd86-c605-4ada-ba3a-1708e75fc876\n",
      "replaying from journal 1970-01-05T124000.000000Z--1970-01-05T124000.000000Z--new--a5b94332-a395-4da1-a4c9-7a867ddc53f6\n",
      "replaying from journal 1970-01-05T152640.000000Z--1970-01-05T152640.000000Z--new--3288da4a-17f1-44d4-8d5c-865ec84fdfdd\n",
      "b'{\"foo\": 43}'\n",
      "replaying from journal 1970-01-05T181320.000000Z--1970-01-05T181320.000000Z--new--894d9c62-fdae-4f9b-ba2f-c0d8d09303e1\n",
      "b'{\"foo\": 44}'\n",
      "replaying from journal 1970-01-05T210000.000000Z--1970-01-05T210000.000000Z--new--5bfe0732-2fa8-483f-b7d0-9b83cf19f194\n",
      "b'{\"foo\": 45}'\n",
      "replaying from journal 1970-01-05T234640.000000Z--1970-01-05T234640.000000Z--new--05e2ab49-410c-405a-b3ab-7a2da4f2805d\n",
      "b'{\"foo\": 46}'\n",
      "replaying from journal 1970-01-06T023320.000000Z--1970-01-06T023320.000000Z--new--ab5ed194-92bc-448b-afee-7cdb22ba0ada\n",
      "b'{\"foo\": 47}'\n",
      "replaying from journal 1970-01-06T052000.000000Z--1970-01-06T052000.000000Z--new--59c3cad0-af15-41f4-b5d2-3a438841d3cd\n",
      "b'{\"foo\": 48}'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "for i in range(40, 50):\n",
    "    event_data = json.dumps({'foo': i}).encode()\n",
    "    event_uuid = str(uuid.uuid4())\n",
    "    event_date = datetime.datetime.fromtimestamp(10000 * i)\n",
    "    ff.put(event_data, event_uuid, event_date)\n",
    "\n",
    "arbitrary_from_date = datetime.datetime.fromtimestamp(10000 * 42)\n",
    "arbitrary_to_date = datetime.datetime.fromtimestamp(10000 * 48)\n",
    "\n",
    "for event in ff.replay(from_date=arbitrary_from_date, to_date=arbitrary_to_date):\n",
    "    print(event.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the event data is JSON, we can use JMESPath to filter it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaying from journal 1970-01-05T124000.000000Z--1970-01-05T124000.000000Z--new--a5b94332-a395-4da1-a4c9-7a867ddc53f6\n",
      "replaying from journal 1970-01-05T152640.000000Z--1970-01-05T152640.000000Z--new--3288da4a-17f1-44d4-8d5c-865ec84fdfdd\n",
      "replaying from journal 1970-01-05T181320.000000Z--1970-01-05T181320.000000Z--new--894d9c62-fdae-4f9b-ba2f-c0d8d09303e1\n",
      "replaying from journal 1970-01-05T210000.000000Z--1970-01-05T210000.000000Z--new--5bfe0732-2fa8-483f-b7d0-9b83cf19f194\n",
      "replaying from journal 1970-01-05T234640.000000Z--1970-01-05T234640.000000Z--new--05e2ab49-410c-405a-b3ab-7a2da4f2805d\n",
      "replaying from journal 1970-01-06T023320.000000Z--1970-01-06T023320.000000Z--new--ab5ed194-92bc-448b-afee-7cdb22ba0ada\n",
      "replaying from journal 1970-01-06T052000.000000Z--1970-01-06T052000.000000Z--new--59c3cad0-af15-41f4-b5d2-3a438841d3cd\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[43, 44, 45, 46, 47, 48]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jmespath\n",
    "\n",
    "events = []\n",
    "for event in ff.replay(from_date=arbitrary_from_date, to_date=arbitrary_to_date):\n",
    "    events.append(json.loads(event.data))\n",
    "\n",
    "expression = jmespath.compile('events[].foo')\n",
    "expression.search({'events': events})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
